{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "학습의 편의를 위하여 Gensim 에서 제공하는 FastText 를 이용합니다 (Fasebook Research에서 제공하는 FastText을 쓰셔도 됩니다).\n",
    "\n",
    "한글의 FastText 를 적용하려면 초/중/종성을 분리해야 합니다. 이를 위하여 compose, decompose 함수를 이용합니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "from soynlp.hangle import decompose, compose\n",
    "\n",
    "def remove_doublespace(s):  # 띄어쓰기류의 문자가 연속으로 두번 이상 있으면 한번으로 줄입니다.\n",
    "    doublespace_pattern = re.compile('\\s+')\n",
    "    return doublespace_pattern.sub(' ', s).strip()\n",
    "\n",
    "def findrepeat(text):  # 같은 문자가 3번 이상 반복되면 최대 3개만 출력합니다.\n",
    "    for t in set([c for c in text]):\n",
    "        for s, e in reversed([(m.start(), m.end()) for m in re.compile('['+t+']{3,}').finditer(text)]):\n",
    "             text = text[:s] + t*3 + text[e:]\n",
    "    return text\n",
    "\n",
    "def encode(s):  # 한글 초/중/종성 처리\n",
    "    def process(c):\n",
    "        if re.compile('[0-9|a-z|A-Z|.?!]+').match(c):  # 알파벳, 숫자, ., ?, !에 해당하는 문자가 나오면 '-c-' 형식으로 변경\n",
    "            return '-' + c + '-'\n",
    "        jamo = decompose(c)\n",
    "        # 'a' or 모음 or 자음\n",
    "        if (jamo is None):\n",
    "            return ' '\n",
    "        cho, jung, jong = (jamo)\n",
    "        if jong == ' ':\n",
    "            jong = '-'\n",
    "            if jung == ' ':\n",
    "                return '-' + cho + '-'\n",
    "            else:\n",
    "                if cho == ' ':\n",
    "                    cho = '-'\n",
    "        return cho + jung + jong\n",
    "    \n",
    "    s = ''.join(re.compile('[0-9|a-z|A-Z|ㄱ-ㅎ|ㅏ-ㅣ|가-힣|.?!|\\s]+').findall(s))  # compile에 지정한 문자 외에 모두 제거\n",
    "    s = findrepeat(s)\n",
    "    s = ''.join(process(c) for c in s)\n",
    "    return remove_doublespace(s).strip()\n",
    "\n",
    "def decode(s):  # 텍스트 복원\n",
    "    def process(t):\n",
    "        assert len(t) % 3 == 0\n",
    "        t_ = t.replace('-', ' ')\n",
    "        chars = [tuple(t_[3*i:3*(i+1)]) for i in range(len(t_)//3)]\n",
    "        recovered = list()\n",
    "        for char in chars:\n",
    "            try:\n",
    "                recovered.append(compose(*char))\n",
    "            except ValueError:\n",
    "                recovered.append(''.join(char).replace('-', '').strip())\n",
    "        recovered = ''.join(recovered)\n",
    "        return recovered\n",
    "\n",
    "    return ' '.join(process(t) for t in s.split())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "인코딩 결과: -ㄱ--ㅏ-ㄴㅏ-ㅎㅣㅎ-a--0--.--?--!- ㅂㅏㄴㅂㅗㄱ-5--5--5-\n",
      "디코딩 결과: ㄱㅏ나힣a0.?! 반복555\n"
     ]
    }
   ],
   "source": [
    "text = 'ㄱㅏ나힣a0.?!@ 반복55555'\n",
    "print(f'인코딩 결과: {encode(text)}')\n",
    "print(f'디코딩 결과: {decode(encode(text))}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "처리할 리뷰 데이터를 불러옵니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\h2oin\\Anaconda3\\envs\\nlp_env1\\lib\\site-packages\\numpy\\lib\\arraysetops.py:568: FutureWarning: elementwise comparison failed; returning scalar instead, but in the future will perform elementwise comparison\n",
      "  mask |= (ar1 == a)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0                         한글지켜준건 고맙다. 하지만 영화는 엄청 지루하다.\n",
       "1              우리나라 영화계는 반일이랑 518 없으면 영화를 만들지를 못해요....\n",
       "2    어제 메박가서 보고왔는데 솔직히 지루했습니다. 내용전개도 스토리도 특별하지 않구요....\n",
       "3                                      보지마라 존나 지루하고 잔인\n",
       "4                                  지루하고 또 지루하고 그저그런 영화\n",
       "5                                항일, 반일영화만 주구장창 찍어대니 원\n",
       "6                                  재미가 없어용 ㅠ보다 나왔습니다 ㅠ\n",
       "7                                   일케 많이 웃게 하는 영화 첨인듯\n",
       "8                                  별점높아도 기대안했는데 재미있었어요\n",
       "9                                  오랜만에 한국영화 재밌게 봤어요^^\n",
       "Name: review, dtype: object"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "path = './data/nm_review(dropna).tsv'\n",
    "df = pd.read_csv(path, delimiter='\\t', index_col=0)\n",
    "df['review'][:10]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "리뷰 데이터를 인코딩 처리하고 띄어쓰기 단위로 토큰화 합니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wall time: 5min 42s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "corpus = list(map(lambda x:encode(x).split(' '), df['review']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['ㅎㅏㄴㄱㅡㄹㅈㅣ-ㅋㅕ-ㅈㅜㄴㄱㅓㄴ', 'ㄱㅗ-ㅁㅏㅂㄷㅏ--.-', 'ㅎㅏ-ㅈㅣ-ㅁㅏㄴ', 'ㅇㅕㅇㅎㅘ-ㄴㅡㄴ', 'ㅇㅓㅁㅊㅓㅇ', 'ㅈㅣ-ㄹㅜ-ㅎㅏ-ㄷㅏ--.-']\n",
      "['ㅇㅜ-ㄹㅣ-ㄴㅏ-ㄹㅏ-', 'ㅇㅕㅇㅎㅘ-ㄱㅖ-ㄴㅡㄴ', 'ㅂㅏㄴㅇㅣㄹㅇㅣ-ㄹㅏㅇ', '-5--1--8-', 'ㅇㅓㅄㅇㅡ-ㅁㅕㄴ', 'ㅇㅕㅇㅎㅘ-ㄹㅡㄹ', 'ㅁㅏㄴㄷㅡㄹㅈㅣ-ㄹㅡㄹ', 'ㅁㅗㅅㅎㅐ-ㅇㅛ--.--.--.-']\n",
      "['ㅇㅓ-ㅈㅔ-', 'ㅁㅔ-ㅂㅏㄱㄱㅏ-ㅅㅓ-', 'ㅂㅗ-ㄱㅗ-ㅇㅘㅆㄴㅡㄴㄷㅔ-', 'ㅅㅗㄹㅈㅣㄱㅎㅣ-', 'ㅈㅣ-ㄹㅜ-ㅎㅐㅆㅅㅡㅂㄴㅣ-ㄷㅏ--.-', 'ㄴㅐ-ㅇㅛㅇㅈㅓㄴㄱㅐ-ㄷㅗ-', 'ㅅㅡ-ㅌㅗ-ㄹㅣ-ㄷㅗ-', 'ㅌㅡㄱㅂㅕㄹㅎㅏ-ㅈㅣ-', 'ㅇㅏㄶㄱㅜ-ㅇㅛ--.-ㄱㅖ-ㅅㅗㄱ', 'ㅁㅏㄹㅁㅏㄹㅁㅏㄹㅎㅏ-ㄷㅏ-ㄱㅏ-', 'ㄲㅡㅌㄴㅏ-ㄴㅡㄴㄷㅔ-', 'ㄷㅓ-ㄷㅗ-', 'ㄷㅓㄹㄷㅗ-ㅁㅏㄹㄱㅗ-', 'ㄷㅓㄱㅎㅖ-ㅇㅗㅇㅈㅜ-', 'ㅂㅗ-ㄷㅏ-', 'ㅈㅗ-ㄱㅡㅁ', 'ㅇㅏ-ㄹㅐㅅㄱㅡㅂㅇㅢ-', 'ㅇㅕㅇㅎㅘ-ㅇㅕㅆㄷㅓㄴㄱㅓ-', 'ㄱㅏㅌㄴㅔ-ㅇㅛ--.-']\n",
      "['ㅂㅗ-ㅈㅣ-ㅁㅏ-ㄹㅏ-', 'ㅈㅗㄴㄴㅏ-', 'ㅈㅣ-ㄹㅜ-ㅎㅏ-ㄱㅗ-', 'ㅈㅏㄴㅇㅣㄴ']\n",
      "['ㅈㅣ-ㄹㅜ-ㅎㅏ-ㄱㅗ-', 'ㄸㅗ-', 'ㅈㅣ-ㄹㅜ-ㅎㅏ-ㄱㅗ-', 'ㄱㅡ-ㅈㅓ-ㄱㅡ-ㄹㅓㄴ', 'ㅇㅕㅇㅎㅘ-']\n",
      "['ㅎㅏㅇㅇㅣㄹ', 'ㅂㅏㄴㅇㅣㄹㅇㅕㅇㅎㅘ-ㅁㅏㄴ', 'ㅈㅜ-ㄱㅜ-ㅈㅏㅇㅊㅏㅇ', 'ㅉㅣㄱㅇㅓ-ㄷㅐ-ㄴㅣ-', 'ㅇㅝㄴ']\n",
      "['ㅈㅐ-ㅁㅣ-ㄱㅏ-', 'ㅇㅓㅄㅇㅓ-ㅇㅛㅇ', '-ㅠ-ㅂㅗ-ㄷㅏ-', 'ㄴㅏ-ㅇㅘㅆㅅㅡㅂㄴㅣ-ㄷㅏ-', '-ㅠ-']\n",
      "['ㅇㅣㄹㅋㅔ-', 'ㅁㅏㄶㅇㅣ-', 'ㅇㅜㅅㄱㅔ-', 'ㅎㅏ-ㄴㅡㄴ', 'ㅇㅕㅇㅎㅘ-', 'ㅊㅓㅁㅇㅣㄴㄷㅡㅅ']\n",
      "['ㅂㅕㄹㅈㅓㅁㄴㅗㅍㅇㅏ-ㄷㅗ-', 'ㄱㅣ-ㄷㅐ-ㅇㅏㄴㅎㅐㅆㄴㅡㄴㄷㅔ-', 'ㅈㅐ-ㅁㅣ-ㅇㅣㅆㅇㅓㅆㅇㅓ-ㅇㅛ-']\n",
      "['ㅇㅗ-ㄹㅐㄴㅁㅏㄴㅇㅔ-', 'ㅎㅏㄴㄱㅜㄱㅇㅕㅇㅎㅘ-', 'ㅈㅐ-ㅁㅣㅆㄱㅔ-', 'ㅂㅘㅆㅇㅓ-ㅇㅛ-']\n"
     ]
    }
   ],
   "source": [
    "for text in corpus[:10]:\n",
    "    print(text)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "fasttext model 학습"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "FastText의 학습 과정을 볼 수 있도록 logging을 설정합니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import logging\n",
    "logging.basicConfig(format='%(asctime)s : %(levelname)s : %(message)s', level = logging.INFO)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "gensim으로 FastText를 불러온 후 앞서 처리한 데이터를 가지고 학습합니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2019-11-12 23:51:11,953 : INFO : resetting layer weights\n",
      "2019-11-12 23:51:21,620 : INFO : collecting all words and their counts\n",
      "2019-11-12 23:51:21,622 : INFO : PROGRESS: at sentence #0, processed 0 words, keeping 0 word types\n",
      "2019-11-12 23:51:21,687 : INFO : PROGRESS: at sentence #10000, processed 65220 words, keeping 28736 word types\n",
      "2019-11-12 23:51:21,738 : INFO : PROGRESS: at sentence #20000, processed 121855 words, keeping 45143 word types\n",
      "2019-11-12 23:51:21,787 : INFO : PROGRESS: at sentence #30000, processed 174160 words, keeping 58158 word types\n",
      "2019-11-12 23:51:21,837 : INFO : PROGRESS: at sentence #40000, processed 221632 words, keeping 69283 word types\n",
      "2019-11-12 23:51:21,873 : INFO : PROGRESS: at sentence #50000, processed 279556 words, keeping 84308 word types\n",
      "2019-11-12 23:51:21,922 : INFO : PROGRESS: at sentence #60000, processed 341720 words, keeping 99074 word types\n",
      "2019-11-12 23:51:21,963 : INFO : PROGRESS: at sentence #70000, processed 404238 words, keeping 112549 word types\n",
      "2019-11-12 23:51:22,018 : INFO : PROGRESS: at sentence #80000, processed 472467 words, keeping 128010 word types\n",
      "2019-11-12 23:51:22,064 : INFO : PROGRESS: at sentence #90000, processed 538789 words, keeping 142281 word types\n",
      "2019-11-12 23:51:22,134 : INFO : PROGRESS: at sentence #100000, processed 605929 words, keeping 155682 word types\n",
      "2019-11-12 23:51:22,187 : INFO : PROGRESS: at sentence #110000, processed 679666 words, keeping 172118 word types\n",
      "2019-11-12 23:51:22,284 : INFO : PROGRESS: at sentence #120000, processed 755581 words, keeping 188923 word types\n",
      "2019-11-12 23:51:22,381 : INFO : PROGRESS: at sentence #130000, processed 830232 words, keeping 204076 word types\n",
      "2019-11-12 23:51:22,432 : INFO : PROGRESS: at sentence #140000, processed 903941 words, keeping 218030 word types\n",
      "2019-11-12 23:51:22,498 : INFO : PROGRESS: at sentence #150000, processed 977735 words, keeping 231244 word types\n",
      "2019-11-12 23:51:22,560 : INFO : PROGRESS: at sentence #160000, processed 1050122 words, keeping 244558 word types\n",
      "2019-11-12 23:51:22,608 : INFO : PROGRESS: at sentence #170000, processed 1120893 words, keeping 257526 word types\n",
      "2019-11-12 23:51:22,660 : INFO : PROGRESS: at sentence #180000, processed 1194795 words, keeping 271695 word types\n",
      "2019-11-12 23:51:22,721 : INFO : PROGRESS: at sentence #190000, processed 1270482 words, keeping 287056 word types\n",
      "2019-11-12 23:51:22,792 : INFO : PROGRESS: at sentence #200000, processed 1347771 words, keeping 302388 word types\n",
      "2019-11-12 23:51:22,858 : INFO : PROGRESS: at sentence #210000, processed 1420440 words, keeping 315186 word types\n",
      "2019-11-12 23:51:22,927 : INFO : PROGRESS: at sentence #220000, processed 1496545 words, keeping 327522 word types\n",
      "2019-11-12 23:51:23,001 : INFO : PROGRESS: at sentence #230000, processed 1566666 words, keeping 338543 word types\n",
      "2019-11-12 23:51:23,078 : INFO : PROGRESS: at sentence #240000, processed 1645012 words, keeping 352667 word types\n",
      "2019-11-12 23:51:23,130 : INFO : PROGRESS: at sentence #250000, processed 1727266 words, keeping 364124 word types\n",
      "2019-11-12 23:51:23,219 : INFO : PROGRESS: at sentence #260000, processed 1819508 words, keeping 382693 word types\n",
      "2019-11-12 23:51:23,292 : INFO : PROGRESS: at sentence #270000, processed 1901385 words, keeping 399678 word types\n",
      "2019-11-12 23:51:23,341 : INFO : PROGRESS: at sentence #280000, processed 1975088 words, keeping 415957 word types\n",
      "2019-11-12 23:51:23,402 : INFO : PROGRESS: at sentence #290000, processed 2041259 words, keeping 430207 word types\n",
      "2019-11-12 23:51:23,454 : INFO : PROGRESS: at sentence #300000, processed 2101003 words, keeping 441128 word types\n",
      "2019-11-12 23:51:23,511 : INFO : PROGRESS: at sentence #310000, processed 2165464 words, keeping 452654 word types\n",
      "2019-11-12 23:51:23,573 : INFO : PROGRESS: at sentence #320000, processed 2237686 words, keeping 466036 word types\n",
      "2019-11-12 23:51:23,629 : INFO : PROGRESS: at sentence #330000, processed 2311291 words, keeping 480140 word types\n",
      "2019-11-12 23:51:23,696 : INFO : PROGRESS: at sentence #340000, processed 2392319 words, keeping 495787 word types\n",
      "2019-11-12 23:51:23,738 : INFO : PROGRESS: at sentence #350000, processed 2453648 words, keeping 507507 word types\n",
      "2019-11-12 23:51:23,791 : INFO : PROGRESS: at sentence #360000, processed 2515974 words, keeping 518712 word types\n",
      "2019-11-12 23:51:23,840 : INFO : PROGRESS: at sentence #370000, processed 2583761 words, keeping 531136 word types\n",
      "2019-11-12 23:51:23,886 : INFO : PROGRESS: at sentence #380000, processed 2640530 words, keeping 540530 word types\n",
      "2019-11-12 23:51:23,933 : INFO : PROGRESS: at sentence #390000, processed 2709485 words, keeping 552294 word types\n",
      "2019-11-12 23:51:23,986 : INFO : PROGRESS: at sentence #400000, processed 2770996 words, keeping 562203 word types\n",
      "2019-11-12 23:51:24,049 : INFO : PROGRESS: at sentence #410000, processed 2837119 words, keeping 574175 word types\n",
      "2019-11-12 23:51:24,104 : INFO : PROGRESS: at sentence #420000, processed 2900496 words, keeping 585158 word types\n",
      "2019-11-12 23:51:24,174 : INFO : PROGRESS: at sentence #430000, processed 2976158 words, keeping 597390 word types\n",
      "2019-11-12 23:51:24,237 : INFO : PROGRESS: at sentence #440000, processed 3049330 words, keeping 609754 word types\n",
      "2019-11-12 23:51:24,292 : INFO : PROGRESS: at sentence #450000, processed 3124168 words, keeping 620491 word types\n",
      "2019-11-12 23:51:24,358 : INFO : PROGRESS: at sentence #460000, processed 3201473 words, keeping 634496 word types\n",
      "2019-11-12 23:51:24,421 : INFO : PROGRESS: at sentence #470000, processed 3279076 words, keeping 648091 word types\n",
      "2019-11-12 23:51:24,481 : INFO : PROGRESS: at sentence #480000, processed 3355862 words, keeping 660269 word types\n",
      "2019-11-12 23:51:24,552 : INFO : PROGRESS: at sentence #490000, processed 3436042 words, keeping 673913 word types\n",
      "2019-11-12 23:51:24,617 : INFO : PROGRESS: at sentence #500000, processed 3510726 words, keeping 685762 word types\n",
      "2019-11-12 23:51:24,678 : INFO : PROGRESS: at sentence #510000, processed 3582165 words, keeping 697346 word types\n",
      "2019-11-12 23:51:24,789 : INFO : PROGRESS: at sentence #520000, processed 3646370 words, keeping 708439 word types\n",
      "2019-11-12 23:51:24,838 : INFO : PROGRESS: at sentence #530000, processed 3725297 words, keeping 724805 word types\n",
      "2019-11-12 23:51:24,902 : INFO : PROGRESS: at sentence #540000, processed 3809829 words, keeping 740727 word types\n",
      "2019-11-12 23:51:24,945 : INFO : PROGRESS: at sentence #550000, processed 3870760 words, keeping 750197 word types\n",
      "2019-11-12 23:51:25,005 : INFO : PROGRESS: at sentence #560000, processed 3952901 words, keeping 764166 word types\n",
      "2019-11-12 23:51:25,057 : INFO : PROGRESS: at sentence #570000, processed 4017068 words, keeping 774390 word types\n",
      "2019-11-12 23:51:25,108 : INFO : PROGRESS: at sentence #580000, processed 4087767 words, keeping 785214 word types\n",
      "2019-11-12 23:51:25,162 : INFO : PROGRESS: at sentence #590000, processed 4171790 words, keeping 798086 word types\n",
      "2019-11-12 23:51:25,215 : INFO : PROGRESS: at sentence #600000, processed 4237722 words, keeping 809040 word types\n",
      "2019-11-12 23:51:25,266 : INFO : PROGRESS: at sentence #610000, processed 4322551 words, keeping 822064 word types\n",
      "2019-11-12 23:51:25,336 : INFO : PROGRESS: at sentence #620000, processed 4406605 words, keeping 834203 word types\n",
      "2019-11-12 23:51:25,408 : INFO : PROGRESS: at sentence #630000, processed 4496312 words, keeping 845882 word types\n",
      "2019-11-12 23:51:25,495 : INFO : PROGRESS: at sentence #640000, processed 4581033 words, keeping 859749 word types\n",
      "2019-11-12 23:51:25,639 : INFO : PROGRESS: at sentence #650000, processed 4654762 words, keeping 871385 word types\n",
      "2019-11-12 23:51:25,727 : INFO : PROGRESS: at sentence #660000, processed 4727062 words, keeping 882790 word types\n",
      "2019-11-12 23:51:25,783 : INFO : PROGRESS: at sentence #670000, processed 4791737 words, keeping 893015 word types\n",
      "2019-11-12 23:51:25,832 : INFO : PROGRESS: at sentence #680000, processed 4855865 words, keeping 902809 word types\n",
      "2019-11-12 23:51:25,883 : INFO : PROGRESS: at sentence #690000, processed 4920466 words, keeping 912689 word types\n",
      "2019-11-12 23:51:25,942 : INFO : PROGRESS: at sentence #700000, processed 4983540 words, keeping 923420 word types\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2019-11-12 23:51:25,992 : INFO : PROGRESS: at sentence #710000, processed 5045533 words, keeping 933254 word types\n",
      "2019-11-12 23:51:26,042 : INFO : PROGRESS: at sentence #720000, processed 5105721 words, keeping 942799 word types\n",
      "2019-11-12 23:51:26,104 : INFO : PROGRESS: at sentence #730000, processed 5173122 words, keeping 953709 word types\n",
      "2019-11-12 23:51:26,153 : INFO : PROGRESS: at sentence #740000, processed 5244974 words, keeping 965125 word types\n",
      "2019-11-12 23:51:26,199 : INFO : PROGRESS: at sentence #750000, processed 5315437 words, keeping 976344 word types\n",
      "2019-11-12 23:51:26,260 : INFO : PROGRESS: at sentence #760000, processed 5393395 words, keeping 990023 word types\n",
      "2019-11-12 23:51:26,325 : INFO : PROGRESS: at sentence #770000, processed 5472720 words, keeping 1002677 word types\n",
      "2019-11-12 23:51:26,396 : INFO : PROGRESS: at sentence #780000, processed 5538587 words, keeping 1011713 word types\n",
      "2019-11-12 23:51:26,452 : INFO : PROGRESS: at sentence #790000, processed 5613979 words, keeping 1022218 word types\n",
      "2019-11-12 23:51:26,510 : INFO : PROGRESS: at sentence #800000, processed 5695063 words, keeping 1035592 word types\n",
      "2019-11-12 23:51:26,553 : INFO : PROGRESS: at sentence #810000, processed 5774605 words, keeping 1046611 word types\n",
      "2019-11-12 23:51:26,605 : INFO : PROGRESS: at sentence #820000, processed 5856507 words, keeping 1057080 word types\n",
      "2019-11-12 23:51:26,673 : INFO : PROGRESS: at sentence #830000, processed 5939886 words, keeping 1069422 word types\n",
      "2019-11-12 23:51:26,728 : INFO : PROGRESS: at sentence #840000, processed 6012284 words, keeping 1079986 word types\n",
      "2019-11-12 23:51:26,798 : INFO : PROGRESS: at sentence #850000, processed 6082979 words, keeping 1090781 word types\n",
      "2019-11-12 23:51:26,853 : INFO : PROGRESS: at sentence #860000, processed 6150701 words, keeping 1101937 word types\n",
      "2019-11-12 23:51:26,914 : INFO : PROGRESS: at sentence #870000, processed 6223488 words, keeping 1114048 word types\n",
      "2019-11-12 23:51:26,977 : INFO : PROGRESS: at sentence #880000, processed 6298742 words, keeping 1125464 word types\n",
      "2019-11-12 23:51:27,037 : INFO : PROGRESS: at sentence #890000, processed 6370880 words, keeping 1135693 word types\n",
      "2019-11-12 23:51:27,091 : INFO : PROGRESS: at sentence #900000, processed 6443810 words, keeping 1146542 word types\n",
      "2019-11-12 23:51:27,156 : INFO : PROGRESS: at sentence #910000, processed 6515086 words, keeping 1156665 word types\n",
      "2019-11-12 23:51:27,222 : INFO : PROGRESS: at sentence #920000, processed 6585958 words, keeping 1165972 word types\n",
      "2019-11-12 23:51:27,290 : INFO : PROGRESS: at sentence #930000, processed 6658182 words, keeping 1174603 word types\n",
      "2019-11-12 23:51:27,354 : INFO : PROGRESS: at sentence #940000, processed 6736430 words, keeping 1184661 word types\n",
      "2019-11-12 23:51:27,425 : INFO : PROGRESS: at sentence #950000, processed 6819388 words, keeping 1196048 word types\n",
      "2019-11-12 23:51:27,492 : INFO : PROGRESS: at sentence #960000, processed 6903639 words, keeping 1207004 word types\n",
      "2019-11-12 23:51:27,568 : INFO : PROGRESS: at sentence #970000, processed 6992613 words, keeping 1219214 word types\n",
      "2019-11-12 23:51:27,650 : INFO : PROGRESS: at sentence #980000, processed 7073628 words, keeping 1230703 word types\n",
      "2019-11-12 23:51:27,716 : INFO : PROGRESS: at sentence #990000, processed 7149599 words, keeping 1241511 word types\n",
      "2019-11-12 23:51:27,811 : INFO : PROGRESS: at sentence #1000000, processed 7226908 words, keeping 1251425 word types\n",
      "2019-11-12 23:51:27,868 : INFO : PROGRESS: at sentence #1010000, processed 7306527 words, keeping 1261631 word types\n",
      "2019-11-12 23:51:27,930 : INFO : PROGRESS: at sentence #1020000, processed 7391814 words, keeping 1273436 word types\n",
      "2019-11-12 23:51:27,982 : INFO : PROGRESS: at sentence #1030000, processed 7464065 words, keeping 1281698 word types\n",
      "2019-11-12 23:51:28,038 : INFO : PROGRESS: at sentence #1040000, processed 7544633 words, keeping 1290306 word types\n",
      "2019-11-12 23:51:28,105 : INFO : PROGRESS: at sentence #1050000, processed 7623132 words, keeping 1300219 word types\n",
      "2019-11-12 23:51:28,165 : INFO : PROGRESS: at sentence #1060000, processed 7703898 words, keeping 1313040 word types\n",
      "2019-11-12 23:51:28,223 : INFO : PROGRESS: at sentence #1070000, processed 7787176 words, keeping 1325122 word types\n",
      "2019-11-12 23:51:28,275 : INFO : PROGRESS: at sentence #1080000, processed 7863526 words, keeping 1335235 word types\n",
      "2019-11-12 23:51:28,324 : INFO : PROGRESS: at sentence #1090000, processed 7935765 words, keeping 1344836 word types\n",
      "2019-11-12 23:51:28,392 : INFO : PROGRESS: at sentence #1100000, processed 8009270 words, keeping 1354609 word types\n",
      "2019-11-12 23:51:28,446 : INFO : PROGRESS: at sentence #1110000, processed 8086366 words, keeping 1364939 word types\n",
      "2019-11-12 23:51:28,532 : INFO : PROGRESS: at sentence #1120000, processed 8159592 words, keeping 1374297 word types\n",
      "2019-11-12 23:51:28,610 : INFO : PROGRESS: at sentence #1130000, processed 8230920 words, keeping 1383434 word types\n",
      "2019-11-12 23:51:28,695 : INFO : PROGRESS: at sentence #1140000, processed 8314898 words, keeping 1395148 word types\n",
      "2019-11-12 23:51:28,914 : INFO : PROGRESS: at sentence #1150000, processed 8391503 words, keeping 1406437 word types\n",
      "2019-11-12 23:51:28,977 : INFO : PROGRESS: at sentence #1160000, processed 8472047 words, keeping 1417784 word types\n",
      "2019-11-12 23:51:29,023 : INFO : PROGRESS: at sentence #1170000, processed 8548379 words, keeping 1428109 word types\n",
      "2019-11-12 23:51:29,075 : INFO : PROGRESS: at sentence #1180000, processed 8626352 words, keeping 1438532 word types\n",
      "2019-11-12 23:51:29,122 : INFO : PROGRESS: at sentence #1190000, processed 8704890 words, keeping 1448942 word types\n",
      "2019-11-12 23:51:29,162 : INFO : collected 1458430 word types from a corpus of 8774744 raw words and 1198688 sentences\n",
      "2019-11-12 23:51:29,163 : INFO : Loading a fresh vocabulary\n",
      "2019-11-12 23:51:29,908 : INFO : effective_min_count=10 retains 63056 unique words (4% of original 1458430, drops 1395374)\n",
      "2019-11-12 23:51:29,909 : INFO : effective_min_count=10 leaves 6776141 word corpus (77% of original 8774744, drops 1998603)\n",
      "2019-11-12 23:51:30,147 : INFO : deleting the raw counts dictionary of 1458430 items\n",
      "2019-11-12 23:51:30,180 : INFO : sample=0.001 downsamples 20 most-common words\n",
      "2019-11-12 23:51:30,182 : INFO : downsampling leaves estimated 6496448 word corpus (95.9% of prior 6776141)\n",
      "2019-11-12 23:51:32,352 : INFO : estimated required memory for 63056 words, 522089 buckets and 128 dimensions: 396558328 bytes\n",
      "2019-11-12 23:51:32,384 : INFO : resetting layer weights\n",
      "2019-11-12 23:51:51,967 : INFO : training model with 3 workers on 63056 vocabulary and 128 features, using sg=0 hs=0 sample=0.001 negative=5 window=3\n",
      "2019-11-12 23:51:53,032 : INFO : EPOCH 1 - PROGRESS: at 1.80% examples, 93706 words/s, in_qsize 6, out_qsize 0\n",
      "2019-11-12 23:51:54,047 : INFO : EPOCH 1 - PROGRESS: at 4.31% examples, 106124 words/s, in_qsize 6, out_qsize 1\n",
      "2019-11-12 23:51:55,111 : INFO : EPOCH 1 - PROGRESS: at 6.52% examples, 111134 words/s, in_qsize 6, out_qsize 0\n",
      "2019-11-12 23:51:56,160 : INFO : EPOCH 1 - PROGRESS: at 8.62% examples, 113834 words/s, in_qsize 5, out_qsize 0\n",
      "2019-11-12 23:51:57,187 : INFO : EPOCH 1 - PROGRESS: at 10.49% examples, 115847 words/s, in_qsize 5, out_qsize 0\n",
      "2019-11-12 23:51:58,226 : INFO : EPOCH 1 - PROGRESS: at 12.41% examples, 117350 words/s, in_qsize 6, out_qsize 0\n",
      "2019-11-12 23:51:59,287 : INFO : EPOCH 1 - PROGRESS: at 14.40% examples, 117916 words/s, in_qsize 6, out_qsize 0\n",
      "2019-11-12 23:52:00,296 : INFO : EPOCH 1 - PROGRESS: at 16.28% examples, 118842 words/s, in_qsize 5, out_qsize 0\n",
      "2019-11-12 23:52:01,301 : INFO : EPOCH 1 - PROGRESS: at 18.06% examples, 118893 words/s, in_qsize 5, out_qsize 0\n",
      "2019-11-12 23:52:02,309 : INFO : EPOCH 1 - PROGRESS: at 19.96% examples, 119658 words/s, in_qsize 6, out_qsize 0\n",
      "2019-11-12 23:52:03,348 : INFO : EPOCH 1 - PROGRESS: at 21.52% examples, 119477 words/s, in_qsize 5, out_qsize 0\n",
      "2019-11-12 23:52:04,356 : INFO : EPOCH 1 - PROGRESS: at 23.40% examples, 120218 words/s, in_qsize 6, out_qsize 0\n",
      "2019-11-12 23:52:05,421 : INFO : EPOCH 1 - PROGRESS: at 25.67% examples, 119896 words/s, in_qsize 6, out_qsize 0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2019-11-12 23:52:06,466 : INFO : EPOCH 1 - PROGRESS: at 27.71% examples, 120361 words/s, in_qsize 6, out_qsize 0\n",
      "2019-11-12 23:52:07,496 : INFO : EPOCH 1 - PROGRESS: at 29.96% examples, 120853 words/s, in_qsize 6, out_qsize 0\n",
      "2019-11-12 23:52:08,510 : INFO : EPOCH 1 - PROGRESS: at 32.25% examples, 121502 words/s, in_qsize 6, out_qsize 0\n",
      "2019-11-12 23:52:09,513 : INFO : EPOCH 1 - PROGRESS: at 34.62% examples, 122136 words/s, in_qsize 6, out_qsize 0\n",
      "2019-11-12 23:52:10,615 : INFO : EPOCH 1 - PROGRESS: at 36.79% examples, 122437 words/s, in_qsize 6, out_qsize 0\n",
      "2019-11-12 23:52:11,675 : INFO : EPOCH 1 - PROGRESS: at 38.78% examples, 122565 words/s, in_qsize 5, out_qsize 0\n",
      "2019-11-12 23:52:12,685 : INFO : EPOCH 1 - PROGRESS: at 40.58% examples, 122704 words/s, in_qsize 6, out_qsize 0\n",
      "2019-11-12 23:52:13,697 : INFO : EPOCH 1 - PROGRESS: at 42.36% examples, 122453 words/s, in_qsize 5, out_qsize 0\n",
      "2019-11-12 23:52:14,701 : INFO : EPOCH 1 - PROGRESS: at 44.53% examples, 122920 words/s, in_qsize 6, out_qsize 0\n",
      "2019-11-12 23:52:15,701 : INFO : EPOCH 1 - PROGRESS: at 46.56% examples, 123285 words/s, in_qsize 6, out_qsize 0\n",
      "2019-11-12 23:52:16,736 : INFO : EPOCH 1 - PROGRESS: at 48.70% examples, 123519 words/s, in_qsize 5, out_qsize 0\n",
      "2019-11-12 23:52:17,760 : INFO : EPOCH 1 - PROGRESS: at 50.64% examples, 123768 words/s, in_qsize 5, out_qsize 0\n",
      "2019-11-12 23:52:18,832 : INFO : EPOCH 1 - PROGRESS: at 52.39% examples, 123894 words/s, in_qsize 5, out_qsize 0\n",
      "2019-11-12 23:52:19,878 : INFO : EPOCH 1 - PROGRESS: at 54.25% examples, 123998 words/s, in_qsize 5, out_qsize 0\n",
      "2019-11-12 23:52:20,883 : INFO : EPOCH 1 - PROGRESS: at 56.48% examples, 124293 words/s, in_qsize 5, out_qsize 0\n",
      "2019-11-12 23:52:21,898 : INFO : EPOCH 1 - PROGRESS: at 58.57% examples, 124006 words/s, in_qsize 6, out_qsize 0\n",
      "2019-11-12 23:52:22,936 : INFO : EPOCH 1 - PROGRESS: at 61.06% examples, 124350 words/s, in_qsize 5, out_qsize 0\n",
      "2019-11-12 23:52:23,958 : INFO : EPOCH 1 - PROGRESS: at 63.13% examples, 124447 words/s, in_qsize 6, out_qsize 0\n",
      "2019-11-12 23:52:24,973 : INFO : EPOCH 1 - PROGRESS: at 65.06% examples, 124369 words/s, in_qsize 5, out_qsize 0\n",
      "2019-11-12 23:52:26,053 : INFO : EPOCH 1 - PROGRESS: at 66.98% examples, 124290 words/s, in_qsize 5, out_qsize 2\n",
      "2019-11-12 23:52:27,117 : INFO : EPOCH 1 - PROGRESS: at 68.81% examples, 124388 words/s, in_qsize 5, out_qsize 0\n",
      "2019-11-12 23:52:28,117 : INFO : EPOCH 1 - PROGRESS: at 70.96% examples, 124793 words/s, in_qsize 6, out_qsize 0\n",
      "2019-11-12 23:52:29,150 : INFO : EPOCH 1 - PROGRESS: at 72.95% examples, 124592 words/s, in_qsize 5, out_qsize 0\n",
      "2019-11-12 23:52:30,213 : INFO : EPOCH 1 - PROGRESS: at 74.76% examples, 124201 words/s, in_qsize 5, out_qsize 0\n",
      "2019-11-12 23:52:31,331 : INFO : EPOCH 1 - PROGRESS: at 76.18% examples, 122934 words/s, in_qsize 4, out_qsize 1\n",
      "2019-11-12 23:52:32,373 : INFO : EPOCH 1 - PROGRESS: at 78.11% examples, 122946 words/s, in_qsize 6, out_qsize 0\n",
      "2019-11-12 23:52:33,381 : INFO : EPOCH 1 - PROGRESS: at 79.42% examples, 122297 words/s, in_qsize 6, out_qsize 0\n",
      "2019-11-12 23:52:34,438 : INFO : EPOCH 1 - PROGRESS: at 81.15% examples, 122405 words/s, in_qsize 6, out_qsize 0\n",
      "2019-11-12 23:52:35,447 : INFO : EPOCH 1 - PROGRESS: at 82.99% examples, 122458 words/s, in_qsize 5, out_qsize 0\n",
      "2019-11-12 23:52:36,451 : INFO : EPOCH 1 - PROGRESS: at 84.73% examples, 122532 words/s, in_qsize 6, out_qsize 0\n",
      "2019-11-12 23:52:37,579 : INFO : EPOCH 1 - PROGRESS: at 86.58% examples, 122336 words/s, in_qsize 5, out_qsize 0\n",
      "2019-11-12 23:52:38,660 : INFO : EPOCH 1 - PROGRESS: at 88.45% examples, 122338 words/s, in_qsize 5, out_qsize 1\n",
      "2019-11-12 23:52:39,772 : INFO : EPOCH 1 - PROGRESS: at 90.36% examples, 122270 words/s, in_qsize 5, out_qsize 0\n",
      "2019-11-12 23:52:40,822 : INFO : EPOCH 1 - PROGRESS: at 92.36% examples, 122365 words/s, in_qsize 6, out_qsize 0\n",
      "2019-11-12 23:52:41,858 : INFO : EPOCH 1 - PROGRESS: at 94.21% examples, 122231 words/s, in_qsize 5, out_qsize 0\n",
      "2019-11-12 23:52:42,938 : INFO : EPOCH 1 - PROGRESS: at 96.08% examples, 122199 words/s, in_qsize 5, out_qsize 0\n",
      "2019-11-12 23:52:44,022 : INFO : EPOCH 1 - PROGRESS: at 98.00% examples, 122217 words/s, in_qsize 6, out_qsize 0\n",
      "2019-11-12 23:52:44,997 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2019-11-12 23:52:45,068 : INFO : EPOCH 1 - PROGRESS: at 99.90% examples, 122308 words/s, in_qsize 1, out_qsize 1\n",
      "2019-11-12 23:52:45,069 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2019-11-12 23:52:45,107 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2019-11-12 23:52:45,110 : INFO : EPOCH - 1 : training on 8774744 raw words (6496581 effective words) took 53.1s, 122331 effective words/s\n",
      "2019-11-12 23:52:46,139 : INFO : EPOCH 2 - PROGRESS: at 2.27% examples, 117044 words/s, in_qsize 6, out_qsize 0\n",
      "2019-11-12 23:52:47,155 : INFO : EPOCH 2 - PROGRESS: at 4.98% examples, 125176 words/s, in_qsize 6, out_qsize 0\n",
      "2019-11-12 23:52:48,161 : INFO : EPOCH 2 - PROGRESS: at 6.99% examples, 123411 words/s, in_qsize 5, out_qsize 1\n",
      "2019-11-12 23:52:49,220 : INFO : EPOCH 2 - PROGRESS: at 9.18% examples, 124514 words/s, in_qsize 5, out_qsize 0\n",
      "2019-11-12 23:52:50,268 : INFO : EPOCH 2 - PROGRESS: at 10.96% examples, 122598 words/s, in_qsize 5, out_qsize 0\n",
      "2019-11-12 23:52:51,303 : INFO : EPOCH 2 - PROGRESS: at 12.66% examples, 120609 words/s, in_qsize 6, out_qsize 0\n",
      "2019-11-12 23:52:52,318 : INFO : EPOCH 2 - PROGRESS: at 14.63% examples, 121440 words/s, in_qsize 5, out_qsize 0\n",
      "2019-11-12 23:52:53,321 : INFO : EPOCH 2 - PROGRESS: at 16.28% examples, 120182 words/s, in_qsize 6, out_qsize 1\n",
      "2019-11-12 23:52:54,333 : INFO : EPOCH 2 - PROGRESS: at 18.17% examples, 120807 words/s, in_qsize 6, out_qsize 0\n",
      "2019-11-12 23:52:55,409 : INFO : EPOCH 2 - PROGRESS: at 19.85% examples, 119088 words/s, in_qsize 5, out_qsize 0\n",
      "2019-11-12 23:52:56,421 : INFO : EPOCH 2 - PROGRESS: at 21.35% examples, 118588 words/s, in_qsize 5, out_qsize 0\n",
      "2019-11-12 23:52:57,474 : INFO : EPOCH 2 - PROGRESS: at 23.15% examples, 119032 words/s, in_qsize 6, out_qsize 0\n",
      "2019-11-12 23:52:58,498 : INFO : EPOCH 2 - PROGRESS: at 25.68% examples, 120234 words/s, in_qsize 6, out_qsize 0\n",
      "2019-11-12 23:52:59,506 : INFO : EPOCH 2 - PROGRESS: at 27.81% examples, 121498 words/s, in_qsize 6, out_qsize 0\n",
      "2019-11-12 23:53:00,542 : INFO : EPOCH 2 - PROGRESS: at 29.96% examples, 121397 words/s, in_qsize 6, out_qsize 0\n",
      "2019-11-12 23:53:01,564 : INFO : EPOCH 2 - PROGRESS: at 31.92% examples, 120596 words/s, in_qsize 6, out_qsize 0\n",
      "2019-11-12 23:53:02,575 : INFO : EPOCH 2 - PROGRESS: at 34.48% examples, 122089 words/s, in_qsize 6, out_qsize 0\n",
      "2019-11-12 23:53:03,685 : INFO : EPOCH 2 - PROGRESS: at 36.70% examples, 122335 words/s, in_qsize 5, out_qsize 0\n",
      "2019-11-12 23:53:04,702 : INFO : EPOCH 2 - PROGRESS: at 38.32% examples, 121622 words/s, in_qsize 5, out_qsize 0\n",
      "2019-11-12 23:53:05,801 : INFO : EPOCH 2 - PROGRESS: at 39.97% examples, 120561 words/s, in_qsize 6, out_qsize 0\n",
      "2019-11-12 23:53:06,811 : INFO : EPOCH 2 - PROGRESS: at 41.57% examples, 120061 words/s, in_qsize 6, out_qsize 0\n",
      "2019-11-12 23:53:07,902 : INFO : EPOCH 2 - PROGRESS: at 43.62% examples, 119752 words/s, in_qsize 6, out_qsize 0\n",
      "2019-11-12 23:53:08,958 : INFO : EPOCH 2 - PROGRESS: at 45.29% examples, 119168 words/s, in_qsize 5, out_qsize 1\n",
      "2019-11-12 23:53:09,961 : INFO : EPOCH 2 - PROGRESS: at 47.14% examples, 119080 words/s, in_qsize 6, out_qsize 0\n",
      "2019-11-12 23:53:10,988 : INFO : EPOCH 2 - PROGRESS: at 48.79% examples, 118380 words/s, in_qsize 5, out_qsize 0\n",
      "2019-11-12 23:53:12,003 : INFO : EPOCH 2 - PROGRESS: at 50.55% examples, 118301 words/s, in_qsize 6, out_qsize 0\n",
      "2019-11-12 23:53:13,039 : INFO : EPOCH 2 - PROGRESS: at 52.02% examples, 117957 words/s, in_qsize 5, out_qsize 1\n",
      "2019-11-12 23:53:14,076 : INFO : EPOCH 2 - PROGRESS: at 53.67% examples, 118075 words/s, in_qsize 5, out_qsize 0\n",
      "2019-11-12 23:53:15,082 : INFO : EPOCH 2 - PROGRESS: at 55.71% examples, 118304 words/s, in_qsize 5, out_qsize 0\n",
      "2019-11-12 23:53:16,087 : INFO : EPOCH 2 - PROGRESS: at 57.93% examples, 118523 words/s, in_qsize 5, out_qsize 0\n",
      "2019-11-12 23:53:17,211 : INFO : EPOCH 2 - PROGRESS: at 60.48% examples, 118699 words/s, in_qsize 5, out_qsize 0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2019-11-12 23:53:18,306 : INFO : EPOCH 2 - PROGRESS: at 62.59% examples, 118745 words/s, in_qsize 6, out_qsize 0\n",
      "2019-11-12 23:53:19,355 : INFO : EPOCH 2 - PROGRESS: at 64.55% examples, 118889 words/s, in_qsize 5, out_qsize 0\n",
      "2019-11-12 23:53:20,455 : INFO : EPOCH 2 - PROGRESS: at 66.55% examples, 118921 words/s, in_qsize 4, out_qsize 1\n",
      "2019-11-12 23:53:21,592 : INFO : EPOCH 2 - PROGRESS: at 68.41% examples, 118927 words/s, in_qsize 6, out_qsize 1\n",
      "2019-11-12 23:53:22,663 : INFO : EPOCH 2 - PROGRESS: at 70.38% examples, 119053 words/s, in_qsize 6, out_qsize 0\n",
      "2019-11-12 23:53:23,725 : INFO : EPOCH 2 - PROGRESS: at 72.50% examples, 119122 words/s, in_qsize 5, out_qsize 0\n",
      "2019-11-12 23:53:24,796 : INFO : EPOCH 2 - PROGRESS: at 74.53% examples, 119226 words/s, in_qsize 6, out_qsize 0\n",
      "2019-11-12 23:53:25,862 : INFO : EPOCH 2 - PROGRESS: at 76.64% examples, 119386 words/s, in_qsize 5, out_qsize 0\n",
      "2019-11-12 23:53:26,945 : INFO : EPOCH 2 - PROGRESS: at 78.42% examples, 119190 words/s, in_qsize 6, out_qsize 0\n",
      "2019-11-12 23:53:28,044 : INFO : EPOCH 2 - PROGRESS: at 80.12% examples, 119105 words/s, in_qsize 6, out_qsize 0\n",
      "2019-11-12 23:53:29,055 : INFO : EPOCH 2 - PROGRESS: at 81.37% examples, 118546 words/s, in_qsize 6, out_qsize 0\n",
      "2019-11-12 23:53:30,062 : INFO : EPOCH 2 - PROGRESS: at 82.67% examples, 117866 words/s, in_qsize 4, out_qsize 1\n",
      "2019-11-12 23:53:31,077 : INFO : EPOCH 2 - PROGRESS: at 84.46% examples, 118024 words/s, in_qsize 6, out_qsize 0\n",
      "2019-11-12 23:53:32,102 : INFO : EPOCH 2 - PROGRESS: at 86.05% examples, 117846 words/s, in_qsize 5, out_qsize 0\n",
      "2019-11-12 23:53:33,118 : INFO : EPOCH 2 - PROGRESS: at 87.43% examples, 117427 words/s, in_qsize 6, out_qsize 0\n",
      "2019-11-12 23:53:34,130 : INFO : EPOCH 2 - PROGRESS: at 88.86% examples, 117041 words/s, in_qsize 6, out_qsize 0\n",
      "2019-11-12 23:53:35,135 : INFO : EPOCH 2 - PROGRESS: at 90.24% examples, 116620 words/s, in_qsize 5, out_qsize 0\n",
      "2019-11-12 23:53:36,158 : INFO : EPOCH 2 - PROGRESS: at 91.73% examples, 116178 words/s, in_qsize 5, out_qsize 0\n",
      "2019-11-12 23:53:37,162 : INFO : EPOCH 2 - PROGRESS: at 93.04% examples, 115648 words/s, in_qsize 5, out_qsize 0\n",
      "2019-11-12 23:53:38,205 : INFO : EPOCH 2 - PROGRESS: at 94.72% examples, 115469 words/s, in_qsize 6, out_qsize 0\n",
      "2019-11-12 23:53:39,336 : INFO : EPOCH 2 - PROGRESS: at 96.39% examples, 115202 words/s, in_qsize 6, out_qsize 0\n",
      "2019-11-12 23:53:40,409 : INFO : EPOCH 2 - PROGRESS: at 98.00% examples, 114982 words/s, in_qsize 6, out_qsize 0\n",
      "2019-11-12 23:53:41,435 : INFO : EPOCH 2 - PROGRESS: at 99.68% examples, 114983 words/s, in_qsize 2, out_qsize 2\n",
      "2019-11-12 23:53:41,438 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2019-11-12 23:53:41,509 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2019-11-12 23:53:41,607 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2019-11-12 23:53:41,608 : INFO : EPOCH - 2 : training on 8774744 raw words (6496067 effective words) took 56.5s, 114999 effective words/s\n",
      "2019-11-12 23:53:42,702 : INFO : EPOCH 3 - PROGRESS: at 1.95% examples, 96278 words/s, in_qsize 5, out_qsize 1\n",
      "2019-11-12 23:53:43,863 : INFO : EPOCH 3 - PROGRESS: at 4.72% examples, 106741 words/s, in_qsize 5, out_qsize 0\n",
      "2019-11-12 23:53:44,972 : INFO : EPOCH 3 - PROGRESS: at 6.64% examples, 105275 words/s, in_qsize 5, out_qsize 0\n",
      "2019-11-12 23:53:46,017 : INFO : EPOCH 3 - PROGRESS: at 8.51% examples, 105942 words/s, in_qsize 6, out_qsize 0\n",
      "2019-11-12 23:53:47,115 : INFO : EPOCH 3 - PROGRESS: at 10.17% examples, 105181 words/s, in_qsize 6, out_qsize 0\n",
      "2019-11-12 23:53:48,253 : INFO : EPOCH 3 - PROGRESS: at 11.85% examples, 104342 words/s, in_qsize 4, out_qsize 1\n",
      "2019-11-12 23:53:49,267 : INFO : EPOCH 3 - PROGRESS: at 13.46% examples, 104441 words/s, in_qsize 5, out_qsize 0\n",
      "2019-11-12 23:53:50,295 : INFO : EPOCH 3 - PROGRESS: at 14.96% examples, 103331 words/s, in_qsize 5, out_qsize 0\n",
      "2019-11-12 23:53:51,301 : INFO : EPOCH 3 - PROGRESS: at 16.38% examples, 102568 words/s, in_qsize 5, out_qsize 0\n",
      "2019-11-12 23:53:52,322 : INFO : EPOCH 3 - PROGRESS: at 17.84% examples, 101878 words/s, in_qsize 5, out_qsize 0\n",
      "2019-11-12 23:53:53,404 : INFO : EPOCH 3 - PROGRESS: at 19.44% examples, 101522 words/s, in_qsize 6, out_qsize 1\n",
      "2019-11-12 23:53:54,473 : INFO : EPOCH 3 - PROGRESS: at 20.68% examples, 100230 words/s, in_qsize 6, out_qsize 0\n",
      "2019-11-12 23:53:55,551 : INFO : EPOCH 3 - PROGRESS: at 21.78% examples, 98882 words/s, in_qsize 5, out_qsize 0\n",
      "2019-11-12 23:53:56,620 : INFO : EPOCH 3 - PROGRESS: at 23.40% examples, 99008 words/s, in_qsize 6, out_qsize 0\n",
      "2019-11-12 23:53:57,668 : INFO : EPOCH 3 - PROGRESS: at 25.13% examples, 98405 words/s, in_qsize 5, out_qsize 0\n",
      "2019-11-12 23:53:58,733 : INFO : EPOCH 3 - PROGRESS: at 26.91% examples, 98722 words/s, in_qsize 5, out_qsize 0\n",
      "2019-11-12 23:53:59,830 : INFO : EPOCH 3 - PROGRESS: at 28.44% examples, 98377 words/s, in_qsize 6, out_qsize 0\n",
      "2019-11-12 23:54:00,914 : INFO : EPOCH 3 - PROGRESS: at 30.48% examples, 98577 words/s, in_qsize 6, out_qsize 0\n",
      "2019-11-12 23:54:02,004 : INFO : EPOCH 3 - PROGRESS: at 32.39% examples, 98755 words/s, in_qsize 6, out_qsize 0\n",
      "2019-11-12 23:54:03,009 : INFO : EPOCH 3 - PROGRESS: at 33.93% examples, 98267 words/s, in_qsize 5, out_qsize 0\n",
      "2019-11-12 23:54:04,013 : INFO : EPOCH 3 - PROGRESS: at 35.71% examples, 98430 words/s, in_qsize 6, out_qsize 0\n",
      "2019-11-12 23:54:05,050 : INFO : EPOCH 3 - PROGRESS: at 36.79% examples, 97256 words/s, in_qsize 6, out_qsize 0\n",
      "2019-11-12 23:54:06,063 : INFO : EPOCH 3 - PROGRESS: at 38.10% examples, 96843 words/s, in_qsize 5, out_qsize 0\n",
      "2019-11-12 23:54:07,108 : INFO : EPOCH 3 - PROGRESS: at 39.55% examples, 96651 words/s, in_qsize 5, out_qsize 0\n",
      "2019-11-12 23:54:08,123 : INFO : EPOCH 3 - PROGRESS: at 40.36% examples, 95193 words/s, in_qsize 5, out_qsize 1\n",
      "2019-11-12 23:54:09,268 : INFO : EPOCH 3 - PROGRESS: at 41.69% examples, 94468 words/s, in_qsize 6, out_qsize 1\n",
      "2019-11-12 23:54:10,270 : INFO : EPOCH 3 - PROGRESS: at 43.30% examples, 94500 words/s, in_qsize 6, out_qsize 0\n",
      "2019-11-12 23:54:11,433 : INFO : EPOCH 3 - PROGRESS: at 44.72% examples, 94050 words/s, in_qsize 5, out_qsize 0\n",
      "2019-11-12 23:54:12,443 : INFO : EPOCH 3 - PROGRESS: at 46.27% examples, 94084 words/s, in_qsize 5, out_qsize 0\n",
      "2019-11-12 23:54:13,457 : INFO : EPOCH 3 - PROGRESS: at 47.69% examples, 93854 words/s, in_qsize 6, out_qsize 0\n",
      "2019-11-12 23:54:14,500 : INFO : EPOCH 3 - PROGRESS: at 49.07% examples, 93819 words/s, in_qsize 5, out_qsize 0\n",
      "2019-11-12 23:54:15,662 : INFO : EPOCH 3 - PROGRESS: at 50.55% examples, 93423 words/s, in_qsize 6, out_qsize 0\n",
      "2019-11-12 23:54:16,684 : INFO : EPOCH 3 - PROGRESS: at 51.83% examples, 93488 words/s, in_qsize 6, out_qsize 0\n",
      "2019-11-12 23:54:17,703 : INFO : EPOCH 3 - PROGRESS: at 52.95% examples, 93334 words/s, in_qsize 6, out_qsize 0\n",
      "2019-11-12 23:54:18,752 : INFO : EPOCH 3 - PROGRESS: at 54.14% examples, 92883 words/s, in_qsize 5, out_qsize 0\n",
      "2019-11-12 23:54:19,757 : INFO : EPOCH 3 - PROGRESS: at 55.59% examples, 92763 words/s, in_qsize 5, out_qsize 0\n",
      "2019-11-12 23:54:20,789 : INFO : EPOCH 3 - PROGRESS: at 57.01% examples, 92398 words/s, in_qsize 5, out_qsize 0\n",
      "2019-11-12 23:54:21,816 : INFO : EPOCH 3 - PROGRESS: at 58.44% examples, 92042 words/s, in_qsize 6, out_qsize 0\n",
      "2019-11-12 23:54:22,819 : INFO : EPOCH 3 - PROGRESS: at 59.95% examples, 91760 words/s, in_qsize 6, out_qsize 0\n",
      "2019-11-12 23:54:23,896 : INFO : EPOCH 3 - PROGRESS: at 61.40% examples, 91498 words/s, in_qsize 6, out_qsize 0\n",
      "2019-11-12 23:54:24,928 : INFO : EPOCH 3 - PROGRESS: at 62.81% examples, 91330 words/s, in_qsize 6, out_qsize 0\n",
      "2019-11-12 23:54:26,034 : INFO : EPOCH 3 - PROGRESS: at 64.17% examples, 91146 words/s, in_qsize 6, out_qsize 0\n",
      "2019-11-12 23:54:27,132 : INFO : EPOCH 3 - PROGRESS: at 65.62% examples, 90918 words/s, in_qsize 6, out_qsize 0\n",
      "2019-11-12 23:54:28,175 : INFO : EPOCH 3 - PROGRESS: at 66.87% examples, 90744 words/s, in_qsize 4, out_qsize 1\n",
      "2019-11-12 23:54:29,208 : INFO : EPOCH 3 - PROGRESS: at 67.99% examples, 90523 words/s, in_qsize 6, out_qsize 0\n",
      "2019-11-12 23:54:30,239 : INFO : EPOCH 3 - PROGRESS: at 69.01% examples, 90128 words/s, in_qsize 6, out_qsize 0\n",
      "2019-11-12 23:54:31,239 : INFO : EPOCH 3 - PROGRESS: at 70.38% examples, 90083 words/s, in_qsize 6, out_qsize 0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2019-11-12 23:54:32,361 : INFO : EPOCH 3 - PROGRESS: at 71.82% examples, 89794 words/s, in_qsize 4, out_qsize 1\n",
      "2019-11-12 23:54:33,458 : INFO : EPOCH 3 - PROGRESS: at 73.17% examples, 89560 words/s, in_qsize 5, out_qsize 0\n",
      "2019-11-12 23:54:34,467 : INFO : EPOCH 3 - PROGRESS: at 74.20% examples, 89100 words/s, in_qsize 6, out_qsize 0\n",
      "2019-11-12 23:54:35,576 : INFO : EPOCH 3 - PROGRESS: at 75.24% examples, 88497 words/s, in_qsize 5, out_qsize 0\n",
      "2019-11-12 23:54:36,679 : INFO : EPOCH 3 - PROGRESS: at 76.64% examples, 88346 words/s, in_qsize 5, out_qsize 0\n",
      "2019-11-12 23:54:37,788 : INFO : EPOCH 3 - PROGRESS: at 78.01% examples, 88224 words/s, in_qsize 5, out_qsize 1\n",
      "2019-11-12 23:54:38,863 : INFO : EPOCH 3 - PROGRESS: at 79.02% examples, 87872 words/s, in_qsize 6, out_qsize 0\n",
      "2019-11-12 23:54:39,903 : INFO : EPOCH 3 - PROGRESS: at 79.82% examples, 87336 words/s, in_qsize 5, out_qsize 0\n",
      "2019-11-12 23:54:40,909 : INFO : EPOCH 3 - PROGRESS: at 80.87% examples, 87228 words/s, in_qsize 5, out_qsize 0\n",
      "2019-11-12 23:54:42,093 : INFO : EPOCH 3 - PROGRESS: at 81.91% examples, 86739 words/s, in_qsize 6, out_qsize 0\n",
      "2019-11-12 23:54:43,243 : INFO : EPOCH 3 - PROGRESS: at 82.88% examples, 86201 words/s, in_qsize 5, out_qsize 0\n",
      "2019-11-12 23:54:44,453 : INFO : EPOCH 3 - PROGRESS: at 83.64% examples, 85379 words/s, in_qsize 6, out_qsize 1\n",
      "2019-11-12 23:54:45,623 : INFO : EPOCH 3 - PROGRESS: at 84.46% examples, 84747 words/s, in_qsize 5, out_qsize 0\n",
      "2019-11-12 23:54:46,733 : INFO : EPOCH 3 - PROGRESS: at 85.72% examples, 84678 words/s, in_qsize 6, out_qsize 0\n",
      "2019-11-12 23:54:47,748 : INFO : EPOCH 3 - PROGRESS: at 86.58% examples, 84308 words/s, in_qsize 6, out_qsize 0\n",
      "2019-11-12 23:54:48,839 : INFO : EPOCH 3 - PROGRESS: at 87.63% examples, 84060 words/s, in_qsize 5, out_qsize 0\n",
      "2019-11-12 23:54:49,851 : INFO : EPOCH 3 - PROGRESS: at 88.76% examples, 83967 words/s, in_qsize 6, out_qsize 0\n",
      "2019-11-12 23:54:50,890 : INFO : EPOCH 3 - PROGRESS: at 89.89% examples, 83879 words/s, in_qsize 6, out_qsize 0\n",
      "2019-11-12 23:54:51,999 : INFO : EPOCH 3 - PROGRESS: at 91.05% examples, 83618 words/s, in_qsize 6, out_qsize 0\n",
      "2019-11-12 23:54:53,040 : INFO : EPOCH 3 - PROGRESS: at 92.06% examples, 83333 words/s, in_qsize 6, out_qsize 0\n",
      "2019-11-12 23:54:54,116 : INFO : EPOCH 3 - PROGRESS: at 93.14% examples, 83123 words/s, in_qsize 5, out_qsize 0\n",
      "2019-11-12 23:54:55,135 : INFO : EPOCH 3 - PROGRESS: at 94.52% examples, 83184 words/s, in_qsize 5, out_qsize 0\n",
      "2019-11-12 23:54:56,265 : INFO : EPOCH 3 - PROGRESS: at 95.88% examples, 83191 words/s, in_qsize 6, out_qsize 0\n",
      "2019-11-12 23:54:57,284 : INFO : EPOCH 3 - PROGRESS: at 97.25% examples, 83334 words/s, in_qsize 5, out_qsize 0\n",
      "2019-11-12 23:54:58,315 : INFO : EPOCH 3 - PROGRESS: at 98.43% examples, 83273 words/s, in_qsize 4, out_qsize 1\n",
      "2019-11-12 23:54:59,471 : INFO : EPOCH 3 - PROGRESS: at 99.68% examples, 83176 words/s, in_qsize 3, out_qsize 0\n",
      "2019-11-12 23:54:59,475 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2019-11-12 23:54:59,477 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2019-11-12 23:54:59,640 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2019-11-12 23:54:59,641 : INFO : EPOCH - 3 : training on 8774744 raw words (6496184 effective words) took 78.0s, 83264 effective words/s\n",
      "2019-11-12 23:55:00,667 : INFO : EPOCH 4 - PROGRESS: at 1.49% examples, 80471 words/s, in_qsize 4, out_qsize 1\n",
      "2019-11-12 23:55:01,671 : INFO : EPOCH 4 - PROGRESS: at 3.49% examples, 85324 words/s, in_qsize 6, out_qsize 1\n",
      "2019-11-12 23:55:02,710 : INFO : EPOCH 4 - PROGRESS: at 5.10% examples, 85859 words/s, in_qsize 5, out_qsize 0\n",
      "2019-11-12 23:55:03,756 : INFO : EPOCH 4 - PROGRESS: at 6.52% examples, 84172 words/s, in_qsize 6, out_qsize 0\n",
      "2019-11-12 23:55:04,823 : INFO : EPOCH 4 - PROGRESS: at 7.78% examples, 81298 words/s, in_qsize 6, out_qsize 0\n",
      "2019-11-12 23:55:05,845 : INFO : EPOCH 4 - PROGRESS: at 8.97% examples, 80117 words/s, in_qsize 5, out_qsize 0\n",
      "2019-11-12 23:55:06,926 : INFO : EPOCH 4 - PROGRESS: at 10.17% examples, 79478 words/s, in_qsize 5, out_qsize 0\n",
      "2019-11-12 23:55:07,976 : INFO : EPOCH 4 - PROGRESS: at 11.52% examples, 80408 words/s, in_qsize 5, out_qsize 0\n",
      "2019-11-12 23:55:09,035 : INFO : EPOCH 4 - PROGRESS: at 12.89% examples, 81105 words/s, in_qsize 6, out_qsize 0\n",
      "2019-11-12 23:55:10,106 : INFO : EPOCH 4 - PROGRESS: at 14.17% examples, 80763 words/s, in_qsize 6, out_qsize 0\n",
      "2019-11-12 23:55:11,198 : INFO : EPOCH 4 - PROGRESS: at 15.29% examples, 79602 words/s, in_qsize 6, out_qsize 0\n",
      "2019-11-12 23:55:12,246 : INFO : EPOCH 4 - PROGRESS: at 16.48% examples, 79440 words/s, in_qsize 5, out_qsize 0\n",
      "2019-11-12 23:55:13,322 : INFO : EPOCH 4 - PROGRESS: at 17.62% examples, 78679 words/s, in_qsize 6, out_qsize 0\n",
      "2019-11-12 23:55:14,359 : INFO : EPOCH 4 - PROGRESS: at 18.98% examples, 79309 words/s, in_qsize 5, out_qsize 0\n",
      "2019-11-12 23:55:15,447 : INFO : EPOCH 4 - PROGRESS: at 20.29% examples, 79577 words/s, in_qsize 5, out_qsize 0\n",
      "2019-11-12 23:55:16,461 : INFO : EPOCH 4 - PROGRESS: at 21.35% examples, 79755 words/s, in_qsize 5, out_qsize 0\n",
      "2019-11-12 23:55:17,602 : INFO : EPOCH 4 - PROGRESS: at 22.60% examples, 79974 words/s, in_qsize 6, out_qsize 0\n",
      "2019-11-12 23:55:18,656 : INFO : EPOCH 4 - PROGRESS: at 24.44% examples, 81175 words/s, in_qsize 5, out_qsize 0\n",
      "2019-11-12 23:55:19,711 : INFO : EPOCH 4 - PROGRESS: at 26.14% examples, 81665 words/s, in_qsize 5, out_qsize 0\n",
      "2019-11-12 23:55:20,897 : INFO : EPOCH 4 - PROGRESS: at 27.81% examples, 82295 words/s, in_qsize 5, out_qsize 0\n",
      "2019-11-12 23:55:21,990 : INFO : EPOCH 4 - PROGRESS: at 29.71% examples, 83175 words/s, in_qsize 6, out_qsize 0\n",
      "2019-11-12 23:55:23,001 : INFO : EPOCH 4 - PROGRESS: at 31.52% examples, 83998 words/s, in_qsize 6, out_qsize 0\n",
      "2019-11-12 23:55:24,044 : INFO : EPOCH 4 - PROGRESS: at 32.79% examples, 83462 words/s, in_qsize 6, out_qsize 0\n",
      "2019-11-12 23:55:25,200 : INFO : EPOCH 4 - PROGRESS: at 34.35% examples, 83146 words/s, in_qsize 5, out_qsize 0\n",
      "2019-11-12 23:55:26,233 : INFO : EPOCH 4 - PROGRESS: at 35.71% examples, 82932 words/s, in_qsize 5, out_qsize 0\n",
      "2019-11-12 23:55:27,236 : INFO : EPOCH 4 - PROGRESS: at 36.79% examples, 82619 words/s, in_qsize 6, out_qsize 0\n",
      "2019-11-12 23:55:28,242 : INFO : EPOCH 4 - PROGRESS: at 38.00% examples, 82557 words/s, in_qsize 6, out_qsize 0\n",
      "2019-11-12 23:55:29,250 : INFO : EPOCH 4 - PROGRESS: at 39.10% examples, 82221 words/s, in_qsize 5, out_qsize 0\n",
      "2019-11-12 23:55:30,306 : INFO : EPOCH 4 - PROGRESS: at 40.17% examples, 81838 words/s, in_qsize 6, out_qsize 0\n",
      "2019-11-12 23:55:31,448 : INFO : EPOCH 4 - PROGRESS: at 41.35% examples, 81444 words/s, in_qsize 6, out_qsize 0\n",
      "2019-11-12 23:55:32,475 : INFO : EPOCH 4 - PROGRESS: at 42.77% examples, 81592 words/s, in_qsize 5, out_qsize 0\n",
      "2019-11-12 23:55:33,576 : INFO : EPOCH 4 - PROGRESS: at 44.62% examples, 82453 words/s, in_qsize 6, out_qsize 0\n",
      "2019-11-12 23:55:34,666 : INFO : EPOCH 4 - PROGRESS: at 46.46% examples, 83240 words/s, in_qsize 6, out_qsize 0\n",
      "2019-11-12 23:55:35,682 : INFO : EPOCH 4 - PROGRESS: at 48.29% examples, 83971 words/s, in_qsize 6, out_qsize 0\n",
      "2019-11-12 23:55:36,723 : INFO : EPOCH 4 - PROGRESS: at 49.96% examples, 84588 words/s, in_qsize 6, out_qsize 0\n",
      "2019-11-12 23:55:37,795 : INFO : EPOCH 4 - PROGRESS: at 51.44% examples, 85152 words/s, in_qsize 6, out_qsize 0\n",
      "2019-11-12 23:55:38,860 : INFO : EPOCH 4 - PROGRESS: at 52.95% examples, 85897 words/s, in_qsize 5, out_qsize 0\n",
      "2019-11-12 23:55:39,898 : INFO : EPOCH 4 - PROGRESS: at 54.59% examples, 86430 words/s, in_qsize 6, out_qsize 0\n",
      "2019-11-12 23:55:40,929 : INFO : EPOCH 4 - PROGRESS: at 56.62% examples, 87139 words/s, in_qsize 5, out_qsize 0\n",
      "2019-11-12 23:55:41,990 : INFO : EPOCH 4 - PROGRESS: at 58.71% examples, 87729 words/s, in_qsize 6, out_qsize 0\n",
      "2019-11-12 23:55:43,072 : INFO : EPOCH 4 - PROGRESS: at 60.83% examples, 88244 words/s, in_qsize 6, out_qsize 1\n",
      "2019-11-12 23:55:44,099 : INFO : EPOCH 4 - PROGRESS: at 62.81% examples, 88990 words/s, in_qsize 5, out_qsize 0\n",
      "2019-11-12 23:55:45,203 : INFO : EPOCH 4 - PROGRESS: at 64.55% examples, 89363 words/s, in_qsize 5, out_qsize 0\n",
      "2019-11-12 23:55:46,204 : INFO : EPOCH 4 - PROGRESS: at 66.34% examples, 89958 words/s, in_qsize 5, out_qsize 0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2019-11-12 23:55:47,211 : INFO : EPOCH 4 - PROGRESS: at 67.79% examples, 90263 words/s, in_qsize 6, out_qsize 0\n",
      "2019-11-12 23:55:48,212 : INFO : EPOCH 4 - PROGRESS: at 69.54% examples, 91001 words/s, in_qsize 5, out_qsize 0\n",
      "2019-11-12 23:55:49,268 : INFO : EPOCH 4 - PROGRESS: at 71.58% examples, 91549 words/s, in_qsize 6, out_qsize 0\n",
      "2019-11-12 23:55:50,280 : INFO : EPOCH 4 - PROGRESS: at 73.51% examples, 92132 words/s, in_qsize 6, out_qsize 0\n",
      "2019-11-12 23:55:51,296 : INFO : EPOCH 4 - PROGRESS: at 75.48% examples, 92750 words/s, in_qsize 5, out_qsize 0\n",
      "2019-11-12 23:55:52,302 : INFO : EPOCH 4 - PROGRESS: at 77.35% examples, 93256 words/s, in_qsize 5, out_qsize 0\n",
      "2019-11-12 23:55:53,348 : INFO : EPOCH 4 - PROGRESS: at 79.12% examples, 93816 words/s, in_qsize 5, out_qsize 0\n",
      "2019-11-12 23:55:54,384 : INFO : EPOCH 4 - PROGRESS: at 80.69% examples, 94224 words/s, in_qsize 6, out_qsize 0\n",
      "2019-11-12 23:55:55,427 : INFO : EPOCH 4 - PROGRESS: at 82.45% examples, 94705 words/s, in_qsize 5, out_qsize 0\n",
      "2019-11-12 23:55:56,430 : INFO : EPOCH 4 - PROGRESS: at 84.16% examples, 95145 words/s, in_qsize 6, out_qsize 0\n",
      "2019-11-12 23:55:57,540 : INFO : EPOCH 4 - PROGRESS: at 86.05% examples, 95647 words/s, in_qsize 5, out_qsize 0\n",
      "2019-11-12 23:55:58,675 : INFO : EPOCH 4 - PROGRESS: at 87.93% examples, 96095 words/s, in_qsize 5, out_qsize 0\n",
      "2019-11-12 23:55:59,742 : INFO : EPOCH 4 - PROGRESS: at 89.77% examples, 96573 words/s, in_qsize 5, out_qsize 0\n",
      "2019-11-12 23:56:00,870 : INFO : EPOCH 4 - PROGRESS: at 91.84% examples, 96980 words/s, in_qsize 6, out_qsize 0\n",
      "2019-11-12 23:56:01,880 : INFO : EPOCH 4 - PROGRESS: at 93.64% examples, 97319 words/s, in_qsize 5, out_qsize 0\n",
      "2019-11-12 23:56:02,902 : INFO : EPOCH 4 - PROGRESS: at 95.43% examples, 97717 words/s, in_qsize 5, out_qsize 0\n",
      "2019-11-12 23:56:03,917 : INFO : EPOCH 4 - PROGRESS: at 97.36% examples, 98232 words/s, in_qsize 5, out_qsize 0\n",
      "2019-11-12 23:56:04,918 : INFO : EPOCH 4 - PROGRESS: at 99.18% examples, 98646 words/s, in_qsize 6, out_qsize 0\n",
      "2019-11-12 23:56:05,265 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2019-11-12 23:56:05,288 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2019-11-12 23:56:05,357 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2019-11-12 23:56:05,358 : INFO : EPOCH - 4 : training on 8774744 raw words (6495937 effective words) took 65.7s, 98867 effective words/s\n",
      "2019-11-12 23:56:06,410 : INFO : EPOCH 5 - PROGRESS: at 2.43% examples, 121731 words/s, in_qsize 5, out_qsize 0\n",
      "2019-11-12 23:56:07,453 : INFO : EPOCH 5 - PROGRESS: at 5.10% examples, 125965 words/s, in_qsize 5, out_qsize 0\n",
      "2019-11-12 23:56:08,518 : INFO : EPOCH 5 - PROGRESS: at 7.38% examples, 126380 words/s, in_qsize 5, out_qsize 0\n",
      "2019-11-12 23:56:09,567 : INFO : EPOCH 5 - PROGRESS: at 9.50% examples, 126898 words/s, in_qsize 5, out_qsize 0\n",
      "2019-11-12 23:56:10,649 : INFO : EPOCH 5 - PROGRESS: at 11.41% examples, 125367 words/s, in_qsize 5, out_qsize 0\n",
      "2019-11-12 23:56:11,696 : INFO : EPOCH 5 - PROGRESS: at 13.46% examples, 126281 words/s, in_qsize 6, out_qsize 0\n",
      "2019-11-12 23:56:12,737 : INFO : EPOCH 5 - PROGRESS: at 15.52% examples, 126727 words/s, in_qsize 5, out_qsize 0\n",
      "2019-11-12 23:56:13,759 : INFO : EPOCH 5 - PROGRESS: at 17.38% examples, 126362 words/s, in_qsize 6, out_qsize 0\n",
      "2019-11-12 23:56:14,794 : INFO : EPOCH 5 - PROGRESS: at 19.34% examples, 126163 words/s, in_qsize 5, out_qsize 0\n",
      "2019-11-12 23:56:15,824 : INFO : EPOCH 5 - PROGRESS: at 20.96% examples, 125444 words/s, in_qsize 5, out_qsize 0\n",
      "2019-11-12 23:56:16,923 : INFO : EPOCH 5 - PROGRESS: at 22.72% examples, 124873 words/s, in_qsize 6, out_qsize 0\n",
      "2019-11-12 23:56:17,945 : INFO : EPOCH 5 - PROGRESS: at 25.27% examples, 126185 words/s, in_qsize 5, out_qsize 0\n",
      "2019-11-12 23:56:19,072 : INFO : EPOCH 5 - PROGRESS: at 27.49% examples, 125996 words/s, in_qsize 6, out_qsize 0\n",
      "2019-11-12 23:56:20,100 : INFO : EPOCH 5 - PROGRESS: at 29.71% examples, 126141 words/s, in_qsize 5, out_qsize 0\n",
      "2019-11-12 23:56:21,192 : INFO : EPOCH 5 - PROGRESS: at 32.13% examples, 126306 words/s, in_qsize 6, out_qsize 0\n",
      "2019-11-12 23:56:22,215 : INFO : EPOCH 5 - PROGRESS: at 34.49% examples, 126541 words/s, in_qsize 5, out_qsize 0\n",
      "2019-11-12 23:56:23,216 : INFO : EPOCH 5 - PROGRESS: at 36.55% examples, 126899 words/s, in_qsize 6, out_qsize 0\n",
      "2019-11-12 23:56:24,246 : INFO : EPOCH 5 - PROGRESS: at 38.57% examples, 126978 words/s, in_qsize 5, out_qsize 0\n",
      "2019-11-12 23:56:25,280 : INFO : EPOCH 5 - PROGRESS: at 40.36% examples, 126741 words/s, in_qsize 5, out_qsize 0\n",
      "2019-11-12 23:56:26,295 : INFO : EPOCH 5 - PROGRESS: at 42.22% examples, 126617 words/s, in_qsize 6, out_qsize 0\n",
      "2019-11-12 23:56:27,299 : INFO : EPOCH 5 - PROGRESS: at 44.43% examples, 126942 words/s, in_qsize 5, out_qsize 0\n",
      "2019-11-12 23:56:28,333 : INFO : EPOCH 5 - PROGRESS: at 46.56% examples, 127249 words/s, in_qsize 5, out_qsize 0\n",
      "2019-11-12 23:56:29,351 : INFO : EPOCH 5 - PROGRESS: at 48.70% examples, 127416 words/s, in_qsize 6, out_qsize 0\n",
      "2019-11-12 23:56:30,430 : INFO : EPOCH 5 - PROGRESS: at 50.74% examples, 127523 words/s, in_qsize 5, out_qsize 0\n",
      "2019-11-12 23:56:31,469 : INFO : EPOCH 5 - PROGRESS: at 52.48% examples, 127661 words/s, in_qsize 5, out_qsize 0\n",
      "2019-11-12 23:56:32,533 : INFO : EPOCH 5 - PROGRESS: at 54.36% examples, 127522 words/s, in_qsize 6, out_qsize 0\n",
      "2019-11-12 23:56:33,535 : INFO : EPOCH 5 - PROGRESS: at 56.62% examples, 127717 words/s, in_qsize 5, out_qsize 0\n",
      "2019-11-12 23:56:34,540 : INFO : EPOCH 5 - PROGRESS: at 58.97% examples, 127846 words/s, in_qsize 6, out_qsize 0\n",
      "2019-11-12 23:56:35,676 : INFO : EPOCH 5 - PROGRESS: at 61.40% examples, 127647 words/s, in_qsize 5, out_qsize 0\n",
      "2019-11-12 23:56:36,677 : INFO : EPOCH 5 - PROGRESS: at 63.44% examples, 127694 words/s, in_qsize 6, out_qsize 0\n",
      "2019-11-12 23:56:37,678 : INFO : EPOCH 5 - PROGRESS: at 65.51% examples, 127858 words/s, in_qsize 5, out_qsize 0\n",
      "2019-11-12 23:56:38,768 : INFO : EPOCH 5 - PROGRESS: at 67.39% examples, 127626 words/s, in_qsize 6, out_qsize 0\n",
      "2019-11-12 23:56:39,801 : INFO : EPOCH 5 - PROGRESS: at 69.21% examples, 127700 words/s, in_qsize 6, out_qsize 0\n",
      "2019-11-12 23:56:40,922 : INFO : EPOCH 5 - PROGRESS: at 71.70% examples, 127978 words/s, in_qsize 6, out_qsize 0\n",
      "2019-11-12 23:56:41,961 : INFO : EPOCH 5 - PROGRESS: at 73.97% examples, 128298 words/s, in_qsize 6, out_qsize 0\n",
      "2019-11-12 23:56:43,068 : INFO : EPOCH 5 - PROGRESS: at 76.18% examples, 128251 words/s, in_qsize 5, out_qsize 0\n",
      "2019-11-12 23:56:44,159 : INFO : EPOCH 5 - PROGRESS: at 78.32% examples, 128344 words/s, in_qsize 4, out_qsize 1\n",
      "2019-11-12 23:56:45,204 : INFO : EPOCH 5 - PROGRESS: at 80.12% examples, 128360 words/s, in_qsize 5, out_qsize 0\n",
      "2019-11-12 23:56:46,250 : INFO : EPOCH 5 - PROGRESS: at 82.03% examples, 128505 words/s, in_qsize 6, out_qsize 0\n",
      "2019-11-12 23:56:47,309 : INFO : EPOCH 5 - PROGRESS: at 83.95% examples, 128463 words/s, in_qsize 6, out_qsize 0\n",
      "2019-11-12 23:56:48,344 : INFO : EPOCH 5 - PROGRESS: at 85.84% examples, 128494 words/s, in_qsize 6, out_qsize 0\n",
      "2019-11-12 23:56:49,393 : INFO : EPOCH 5 - PROGRESS: at 87.73% examples, 128526 words/s, in_qsize 5, out_qsize 0\n",
      "2019-11-12 23:56:50,425 : INFO : EPOCH 5 - PROGRESS: at 89.57% examples, 128482 words/s, in_qsize 5, out_qsize 0\n",
      "2019-11-12 23:56:51,464 : INFO : EPOCH 5 - PROGRESS: at 91.62% examples, 128490 words/s, in_qsize 5, out_qsize 0\n",
      "2019-11-12 23:56:52,473 : INFO : EPOCH 5 - PROGRESS: at 93.52% examples, 128424 words/s, in_qsize 5, out_qsize 0\n",
      "2019-11-12 23:56:53,544 : INFO : EPOCH 5 - PROGRESS: at 94.92% examples, 127560 words/s, in_qsize 6, out_qsize 0\n",
      "2019-11-12 23:56:54,549 : INFO : EPOCH 5 - PROGRESS: at 96.59% examples, 127319 words/s, in_qsize 5, out_qsize 0\n",
      "2019-11-12 23:56:55,566 : INFO : EPOCH 5 - PROGRESS: at 98.00% examples, 126661 words/s, in_qsize 5, out_qsize 0\n",
      "2019-11-12 23:56:56,609 : INFO : EPOCH 5 - PROGRESS: at 99.79% examples, 126534 words/s, in_qsize 2, out_qsize 1\n",
      "2019-11-12 23:56:56,610 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2019-11-12 23:56:56,611 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2019-11-12 23:56:56,691 : INFO : worker thread finished; awaiting finish of 0 more threads\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2019-11-12 23:56:56,692 : INFO : EPOCH - 5 : training on 8774744 raw words (6496819 effective words) took 51.3s, 126590 effective words/s\n",
      "2019-11-12 23:56:56,693 : INFO : training on a 43873720 raw words (32481588 effective words) took 304.7s, 106593 effective words/s\n"
     ]
    }
   ],
   "source": [
    "from gensim.models import FastText\n",
    "\n",
    "fasttext_model = FastText(\n",
    "    corpus,  # 처리한 데이터를 할당한 변수를 입력합니다.\n",
    "    size = 128,  # FastText 모델의 벡터 사이즈를 정의합니다.\n",
    "    window = 3,  # 문장 내에서 근접한 단어는 서로 연관있다고 판단합니다. 연속된 몇개의 단어를 연관있다고 할지 정의합니다.\n",
    "    min_count = 10,  # 데이터 내에 적게 나타나는 단어를 무시하여 처리속도를 향상시킵니다. 단어가 몇번 이하로 발견되면 무시할지 정의\n",
    "    min_n = 3,  # FastText는 문자 단위로 단어의 유사도를 판단합니다. n-gram으로 처리할 최소 단위\n",
    "    max_n = 9  # n-gram으로 처리할 최대 단위를 의미합니다.\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "fasttext model save"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2019-11-12 23:58:12,591 : INFO : saving FastText object under ./model/fasttext_model_v2, separately None\n",
      "2019-11-12 23:58:12,592 : INFO : storing np array 'vectors_ngrams' to ./model/fasttext_model_v2.wv.vectors_ngrams.npy\n",
      "2019-11-12 23:58:14,266 : INFO : not storing attribute vectors_ngrams_norm\n",
      "2019-11-12 23:58:14,267 : INFO : not storing attribute vectors_norm\n",
      "2019-11-12 23:58:14,267 : INFO : not storing attribute vectors_vocab_norm\n",
      "2019-11-12 23:58:14,268 : INFO : not storing attribute buckets_word\n",
      "2019-11-12 23:58:14,269 : INFO : storing np array 'vectors_ngrams_lockf' to ./model/fasttext_model_v2.trainables.vectors_ngrams_lockf.npy\n",
      "2019-11-12 23:58:17,390 : INFO : saved ./model/fasttext_model_v2\n"
     ]
    }
   ],
   "source": [
    "fasttext_model.save('./model/fasttext_model')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "fasttext model load"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "from gensim.models import FastText\n",
    "ft_model = FastText.load('./model/fasttext_model')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "fasttext 기능을 사용하기 위해 query string을 초-중-종성 형태로 encoding한 후 사용\n",
    "\n",
    "fasttext 결과를 다시 decoding하여 단어 형태로 변환"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def most_similar2(query, topn=10):\n",
    "    query_ = encode(query)\n",
    "    similars = ft_model.wv.most_similar(query_, topn=topn)\n",
    "    similars = [(decode(word), sim) for word, sim in similars]\n",
    "    return similars"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('재미있음!', 0.9677058458328247),\n",
       " ('재미있엇음', 0.9672262072563171),\n",
       " ('재미있엇다', 0.9540884494781494),\n",
       " ('재미있음ㅋㅋ', 0.9521926641464233),\n",
       " ('재미있었음', 0.946642279624939),\n",
       " ('재밌음요', 0.9405887722969055),\n",
       " ('재미있당', 0.9381404519081116),\n",
       " ('재미있슴', 0.9351725578308105),\n",
       " ('재밌음ㅎ', 0.9349152445793152),\n",
       " ('재미있음!!', 0.9345504641532898)]"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "most_similar2('재미있음')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('재미없엇음', 0.9805892109870911),\n",
       " ('재미없음!', 0.965717077255249),\n",
       " ('재미없어짐', 0.9599900245666504),\n",
       " ('재미없어여', 0.957050085067749),\n",
       " ('재미없었음', 0.9548401832580566),\n",
       " ('재미없슴', 0.9484813213348389),\n",
       " ('ㅈㄴ재미없음', 0.9432206153869629),\n",
       " ('개재미없음', 0.9382390975952148),\n",
       " ('재미없어', 0.9377038478851318),\n",
       " ('재미없음.', 0.9357426166534424)]"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "most_similar2('재미없음')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('재미없진', 0.7632869482040405),\n",
       " ('재미없지', 0.743039608001709),\n",
       " ('재밌진', 0.7236950397491455),\n",
       " ('나쁘진않음', 0.723588228225708),\n",
       " ('재미없지도', 0.7176520228385925),\n",
       " ('재미없지는', 0.7032293677330017),\n",
       " ('재밌지', 0.6922109723091125),\n",
       " ('재밌지?', 0.6894176006317139),\n",
       " ('나쁘지않다', 0.6890566349029541),\n",
       " ('나쁘지않음', 0.6879357099533081)]"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "most_similar2('재미없진않음')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_vector(query, topn=10):\n",
    "    query_ = encode(query)\n",
    "    wv = ft_model.wv.get_vector(query_)\n",
    "    return wv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(128,)"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "get_vector('나쁘지않다고').shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### word vector 생성\n",
    "\n",
    "모든 리뷰의 단어를 word vector로 변환하여 저장하는 과정입니다.\n",
    "\n",
    "이 방법보다는 corpus 내의 모든 단어를 FastText 모델로 벡터화한 사전을 만들고\n",
    "\n",
    "리뷰의 단어 대신 사전의 인덱스를 저장하는 방법이 더 효율적입니다.\n",
    "\n",
    "이 방법은 참고만 하세요."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>code</th>\n",
       "      <th>uid</th>\n",
       "      <th>datetime</th>\n",
       "      <th>score</th>\n",
       "      <th>review</th>\n",
       "      <th>sympathy</th>\n",
       "      <th>notsympathy</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>167699</td>\n",
       "      <td>15108707</td>\n",
       "      <td>2019.01.11 05:36</td>\n",
       "      <td>1</td>\n",
       "      <td>우리나라 영화계는 반일이랑 518 없으면 영화를 만들지를 못해요....</td>\n",
       "      <td>10</td>\n",
       "      <td>19</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>167699</td>\n",
       "      <td>15112721</td>\n",
       "      <td>2019.01.12 09:42</td>\n",
       "      <td>4</td>\n",
       "      <td>어제 메박가서 보고왔는데 솔직히 지루했습니다. 내용전개도 스토리도 특별하지 않구요....</td>\n",
       "      <td>1</td>\n",
       "      <td>11</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>167699</td>\n",
       "      <td>15119773</td>\n",
       "      <td>2019.01.13 16:08</td>\n",
       "      <td>2</td>\n",
       "      <td>보지마라 존나 지루하고 잔인</td>\n",
       "      <td>2</td>\n",
       "      <td>12</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>167651</td>\n",
       "      <td>15189096</td>\n",
       "      <td>2019.01.30 14:48</td>\n",
       "      <td>10</td>\n",
       "      <td>지친 하루를 보냈는데 오랫만에 웃어보았어요.^^</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>164172</td>\n",
       "      <td>15405102</td>\n",
       "      <td>2019.03.12 04:52</td>\n",
       "      <td>8</td>\n",
       "      <td>재밋게 보았음 그냥 기분이 좋아지는 코믹물</td>\n",
       "      <td>5</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>164172</td>\n",
       "      <td>15340125</td>\n",
       "      <td>2019.02.28 21:34</td>\n",
       "      <td>5</td>\n",
       "      <td>그저 그랬다. 별로 웃기지도 않았고 나중에 박성웅 배우님의 연기에 딱 한 번 웃었다.</td>\n",
       "      <td>5</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>177374</td>\n",
       "      <td>15321353</td>\n",
       "      <td>2019.02.24 20:13</td>\n",
       "      <td>10</td>\n",
       "      <td>정우성 연기힘빼고하니까 진짜 좋네여 김향기도 정우성도 넘 감동적ㅜ</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>174050</td>\n",
       "      <td>15509814</td>\n",
       "      <td>2019.04.13 20:27</td>\n",
       "      <td>2</td>\n",
       "      <td>별로였다 전도연나온다길래 기대했는데 설경구 인위적인 눈물연기 봐주기 힘듦</td>\n",
       "      <td>6</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>174050</td>\n",
       "      <td>15508215</td>\n",
       "      <td>2019.04.13 08:11</td>\n",
       "      <td>4</td>\n",
       "      <td>세월호 사건 안타까운거 이미 다 알고 있으니까 제발 영화 소재로는 쓰지 말자.. 유...</td>\n",
       "      <td>6</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>156464</td>\n",
       "      <td>14907556</td>\n",
       "      <td>2018.11.27 08:09</td>\n",
       "      <td>5</td>\n",
       "      <td>그냥 흔하디 흔한 전기영화</td>\n",
       "      <td>5</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     code       uid          datetime  score  \\\n",
       "0  167699  15108707  2019.01.11 05:36      1   \n",
       "1  167699  15112721  2019.01.12 09:42      4   \n",
       "2  167699  15119773  2019.01.13 16:08      2   \n",
       "3  167651  15189096  2019.01.30 14:48     10   \n",
       "4  164172  15405102  2019.03.12 04:52      8   \n",
       "5  164172  15340125  2019.02.28 21:34      5   \n",
       "6  177374  15321353  2019.02.24 20:13     10   \n",
       "7  174050  15509814  2019.04.13 20:27      2   \n",
       "8  174050  15508215  2019.04.13 08:11      4   \n",
       "9  156464  14907556  2018.11.27 08:09      5   \n",
       "\n",
       "                                              review  sympathy  notsympathy  \n",
       "0            우리나라 영화계는 반일이랑 518 없으면 영화를 만들지를 못해요....        10           19  \n",
       "1  어제 메박가서 보고왔는데 솔직히 지루했습니다. 내용전개도 스토리도 특별하지 않구요....         1           11  \n",
       "2                                    보지마라 존나 지루하고 잔인         2           12  \n",
       "3                         지친 하루를 보냈는데 오랫만에 웃어보았어요.^^         1            0  \n",
       "4                            재밋게 보았음 그냥 기분이 좋아지는 코믹물         5            3  \n",
       "5    그저 그랬다. 별로 웃기지도 않았고 나중에 박성웅 배우님의 연기에 딱 한 번 웃었다.         5            3  \n",
       "6               정우성 연기힘빼고하니까 진짜 좋네여 김향기도 정우성도 넘 감동적ㅜ         1            2  \n",
       "7           별로였다 전도연나온다길래 기대했는데 설경구 인위적인 눈물연기 봐주기 힘듦         6            7  \n",
       "8  세월호 사건 안타까운거 이미 다 알고 있으니까 제발 영화 소재로는 쓰지 말자.. 유...         6            7  \n",
       "9                                     그냥 흔하디 흔한 전기영화         5            6  "
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "path = './data/nm_review(score_balanced).tsv'\n",
    "df = pd.read_csv(path, delimiter='\\t', index_col=0)\n",
    "df[:10]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "word vectorizing (unigram -> fasttext)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 / 86750\n",
      "10000 / 86750\n",
      "20000 / 86750\n",
      "30000 / 86750\n",
      "40000 / 86750\n",
      "50000 / 86750\n",
      "60000 / 86750\n",
      "70000 / 86750\n",
      "80000 / 86750\n"
     ]
    }
   ],
   "source": [
    "ug_corpus = list()\n",
    "for row, review in enumerate(df['review']):\n",
    "    if row % 10000 == 0:\n",
    "        print(f'{row} / {df.shape[0]}')\n",
    "    ug_corpus.append(review.split(' '))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['우리나라', '영화계는', '반일이랑', '518', '없으면', '영화를', '만들지를', '못해요....']\n",
      "['어제', '메박가서', '보고왔는데', '솔직히', '지루했습니다.', '내용전개도', '스토리도', '특별하지', '않구요.계속', '말말말하다가', '끝나는데', '더도', '덜도말고', '덕혜옹주', '보다', '조금', '아랫급의', '영화였던거', '같네요.']\n",
      "['보지마라', '존나', '지루하고', '잔인']\n",
      "['지친', '하루를', '보냈는데', '오랫만에', '웃어보았어요.^^']\n",
      "['재밋게', '보았음', '그냥', '기분이', '좋아지는', '코믹물']\n",
      "['그저', '그랬다.', '별로', '웃기지도', '않았고', '나중에', '박성웅', '배우님의', '연기에', '딱', '한', '번', '웃었다.']\n",
      "['정우성', '연기힘빼고하니까', '진짜', '좋네여', '김향기도', '정우성도', '넘', '감동적ㅜ']\n",
      "['별로였다', '전도연나온다길래', '기대했는데', '설경구', '인위적인', '눈물연기', '봐주기', '힘듦']\n",
      "['세월호', '사건', '안타까운거', '이미', '다', '알고', '있으니까', '제발', '영화', '소재로는', '쓰지', '말자..', '유가족들', '두', '번', '죽인다는', '걸', '왜', '몰라', '왜..']\n",
      "['그냥', '흔하디', '흔한', '전기영화']\n"
     ]
    }
   ],
   "source": [
    "for ugs in ug_corpus[:10]:\n",
    "    print(ugs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 / 86750\n",
      "10000 / 86750\n",
      "20000 / 86750\n",
      "30000 / 86750\n",
      "40000 / 86750\n",
      "50000 / 86750\n",
      "60000 / 86750\n",
      "70000 / 86750\n",
      "80000 / 86750\n"
     ]
    }
   ],
   "source": [
    "word_vectors = list()\n",
    "for idx, ugs in enumerate(ug_corpus):\n",
    "    if idx % 10000 == 0:\n",
    "        print(f'{idx} / {len(ug_corpus)}')\n",
    "    word_vectors.append([get_vector(ug) for ug in ugs])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([-0.47300333,  1.30049   , -0.3641767 ,  1.8157151 , -0.85483354,\n",
       "       -0.5684351 , -0.2055265 ,  0.9507764 ,  2.1394181 ,  0.8465369 ,\n",
       "       -0.92357624, -1.2002548 ,  0.55566585, -0.06308649,  0.15278229,\n",
       "        0.00917215,  0.8447812 , -0.54338545, -1.2037055 , -1.6620326 ,\n",
       "       -1.1124866 , -1.0869331 , -0.7396704 , -1.2416005 ,  0.568634  ,\n",
       "        0.4435347 , -0.03420123, -0.84977186, -0.0071111 ,  1.113092  ,\n",
       "        1.654227  ,  0.8370427 ,  0.98035204, -0.92488986,  1.2195312 ,\n",
       "        0.27514252,  0.01439372, -1.5257816 ,  0.35278195,  1.158323  ,\n",
       "       -0.70516914, -1.0562598 , -1.8120387 , -2.3355322 ,  0.06909817,\n",
       "       -0.02377743,  0.06588261,  0.4355864 ,  1.0005324 , -0.07388912,\n",
       "       -0.07517002, -0.34457922,  0.37567556,  2.481846  , -0.22776406,\n",
       "        0.8964096 , -0.5882707 , -0.4701803 , -0.36224553, -0.08499369,\n",
       "       -0.29483414,  0.4539833 ,  0.86328936, -0.63339067,  1.0016291 ,\n",
       "        0.56689465, -1.8571078 ,  0.68104553,  0.27385226, -1.5881224 ,\n",
       "        0.00845931, -0.0809436 , -0.09702054, -1.4528979 , -1.2801718 ,\n",
       "       -1.1514206 ,  0.69064033,  0.31814122,  1.0645453 , -1.1660366 ,\n",
       "       -0.01626997, -2.437083  , -0.34721926,  2.057414  , -0.22467501,\n",
       "        1.4100295 ,  0.25388247,  0.14654079,  0.17709911,  1.1031493 ,\n",
       "       -0.5232119 ,  0.1072446 ,  1.9190779 ,  0.47813922,  0.67262626,\n",
       "       -0.9903951 ,  0.944788  ,  0.14323513,  0.62154335, -0.12624197,\n",
       "       -0.994048  ,  0.6613943 ,  0.1276354 ,  0.21899645,  0.89492136,\n",
       "        0.9925668 ,  0.66503453, -0.7109318 ,  0.5556351 , -0.50393414,\n",
       "        1.0240777 , -0.30695844,  0.3756524 ,  0.18150327,  1.0258968 ,\n",
       "       -1.5751503 ,  0.91764337, -1.4420615 , -0.3094952 ,  1.5705423 ,\n",
       "       -0.22265361, -0.75633   ,  0.47832328, -1.0204068 ,  0.18503861,\n",
       "       -0.16308874, -0.57756716, -0.08047605], dtype=float32)"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "word_vectors[0][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.save('./data/word_vec', word_vectors)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "nlp_env1",
   "language": "python",
   "name": "nlp_env1"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
